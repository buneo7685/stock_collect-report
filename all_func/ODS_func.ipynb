{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import psycopg2\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "conn = psycopg2.connect(host = '127.0.0.1' , dbname = 'postgres' , user = 'postgres' , password = '')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Aggregate 】- All Investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def INSTI_INVESTOR_SUMMARIZE(work_D,cursor):\n",
    "    \n",
    "    cur = cursor\n",
    "    \n",
    "    for D in work_D:\n",
    "        \n",
    "        process_day = '{:0>4}-{:0>2}-{:0>2}'.format(D.year , D.month , D.day)\n",
    "        \n",
    "        cur.execute(\"delete from ods.institutional_investor where date = '{}'\".foramt(process_day), con = conn)\n",
    "        cur.execute(\"commit\")\n",
    "        \n",
    "        ii = pandas.read_sql(\"select main.date , main.no , main.quantity , main.type , d.date_no from \\\n",
    "                         (select date , lpad(no,4,'0') as no , quantity , 'Foreign Investor' as type from foreign_investor where date = '{0}'\\\n",
    "                          union\\\n",
    "                          select date , lpad(no,4,'0') as no , quantity , 'Investment Trust' as type from investment_trust where date = '{0}'\\\n",
    "                          union\\\n",
    "                          select date , lpad(no,4,'0') as no , quantity , 'Dealer' as type from dealer where date = '{0}' ) main join work_date d on main.date = d.date\".format(process_day), con = conn)\n",
    "        \n",
    "        for _ ,data in ii.iterrows():\n",
    "            cur.execute(\"insert into ods.institutional_investor (date ,no , quantity , type , date_no) values (%s,%s,%s,%s,%s)\",data)\n",
    "        cur.execute('commit')\n",
    "        print('【 Institional Investor 】{} data inserted .'.format(process_day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Aggregate 】- Stock SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STOCK_SMA(work_D , cursor):\n",
    "    insert_D = work_D\n",
    "    cur = cursor\n",
    "    \n",
    "    for iD in insert_D:\n",
    "        \n",
    "        # 讀取完整STOCK完整DAILY資料\n",
    "        main = pandas.read_sql(\"select main.*, avg.price as avg_p from (select stock.no , stock.name , stock.close , stock.quantity , stock.date , wk.date_no                              from work_date wk                              left join stock_daily stock                                on wk.date = stock.date ) main                      join stock_daily_avg_price avg on main.date = avg.date and main.no = avg.no \", con = conn)\n",
    "        \n",
    "        # 將欄位 no , name , date 處理成category格式減少記憶體負擔    \n",
    "        main[['no','name']] = main[['no','name']].astype('category')\n",
    "        main['date'] = main['date'].astype('string')\n",
    "        \n",
    "        # 新增每日總量欄位 = 均價 × 張數 \n",
    "        main['amount'] = main.avg_p * main.quantity\n",
    "        main.sort_values(['no','date_no'], inplace = True)\n",
    "        \n",
    "        # 新增前59天JOIN KEY\n",
    "        for i in range(1,60):\n",
    "            main['key_{}'.format(i)] = main['date_no'] - i\n",
    "            main['key_{}'.format(i)] = main['key_{}'.format(i)].astype('category')\n",
    "        \n",
    "        # tmp為LEFT JOIN的表格 ，只留需計算的欄位\n",
    "        tmp = main[['no','date_no','amount','quantity','close']]\n",
    "        \n",
    "        # 取得處理日期的DATE_NO , 並留下需insert的日期資料\n",
    "        iD = '{:0>4}-{:0>2}-{:0>2}'.format(iD.year,iD.month,iD.day)\n",
    "        ino = pandas.read_sql(\"select distinct date_no , date from work_date where date = '{}'\".format(iD) , con = conn)['date_no'][0]\n",
    "        main = main[main['date_no'] == ino]\n",
    "        \n",
    "        print('Start : \\033[1mMERGE\\033[0m data within 60 days')\n",
    "        \n",
    "        # 將60天內的資料合併成一列 , 並刪除join key\n",
    "        for i in range(1,60):\n",
    "            main = pandas.merge(main , tmp , left_on = ['no','key_{}'.format(i)] , right_on = ['no','date_no'] , suffixes = ('','_y_{}'.format(i)))\n",
    "            main.drop(['date_no_y_{}'.format(i),'key_{}'.format(i)], axis = 1 , inplace = True)\n",
    "    \n",
    "        print('Start : \\033[1mAGGREGATE\\033[0m close & average price')   \n",
    "    \n",
    "    # 計算各頻率 SMA & AVG\n",
    "        freq = [5,10,20,60]\n",
    "        for f in freq:\n",
    "            main['sma_{}'.format(f)] = round(main.filter(like = 'close').iloc[:,:f].mean(axis =1),2)\n",
    "            main['amt_{}'.format(f)] = main.filter(like = 'amount').iloc[:,:f].sum(axis =1)\n",
    "            main['qty_{}'.format(f)] = main.filter(like = 'quantity').iloc[:,:f].sum(axis =1)\n",
    "            main['avg_{}'.format(f)] = round((main['amt_{}'.format(f)] / main['qty_{}'.format(f)]),2)\n",
    "            main.drop(['amt_{}'.format(f),'qty_{}'.format(f)] , axis = 1 , inplace = True)        \n",
    "        main.drop(main.filter(regex=r'amount\\_') , axis = 1 , inplace = True )\n",
    "        main.drop(main.filter(regex=r'close\\_') , axis = 1 , inplace = True )\n",
    "        main.drop(main.filter(regex=r'quantity\\_') , axis = 1 , inplace = True )\n",
    "        main['date_no'] = pandas.read_sql(\"select date_no from work_date where date = '{}'\".format(iD) , con = conn )['date_no'][0]\n",
    "        main = main[['date','no','name','close','avg_p','avg_5','avg_10','avg_20','avg_60','sma_5','sma_10','sma_20','sma_60','date_no']]\n",
    "        \n",
    "        print('Start : \\033[1mINSERT\\033[0m to target table')\n",
    "        \n",
    "        if main.shape[0] == 0:\n",
    "            pass\n",
    "        else :\n",
    "            display(main.head(1))\n",
    "            for _ , data in main.iterrows():\n",
    "                cur.execute(\"insert into ods.analyze_avg (date ,no ,name , close ,avg_p ,avg5 ,avg10 ,avg20 ,avg60 ,sma5 ,sma10 ,sma20 ,sma60 , date_no) values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\" , data)\n",
    "            cur.execute('commit')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Aggregate 】- OTC SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OTC_SMA(work_D , cursor):\n",
    "    insert_D = work_D\n",
    "    cur = cursor\n",
    "    \n",
    "    for iD in insert_D:\n",
    "        \n",
    "        # 讀取完整STOCK完整DAILY資料\n",
    "        main = pandas.read_sql(\"select main.*, avg.price as avg_p\\\n",
    "                     from (select stock.no , stock.name , stock.close , stock.quantity , stock.date , wk.date_no \\\n",
    "                             from work_date wk \\\n",
    "                             left join otc_daily stock \\\n",
    "                               on wk.date = stock.date ) main \\\n",
    "                     join stock_daily_avg_price avg on main.date = avg.date and main.no = avg.no \", con = conn)\n",
    "        \n",
    "        # 將欄位 no , name , date 處理成category格式減少記憶體負擔    \n",
    "        main[['no','name']] = main[['no','name']].astype('category')\n",
    "        main['date'] = main['date'].astype('string')\n",
    "        \n",
    "        # 新增每日總量欄位 = 均價 × 張數 \n",
    "        main['amount'] = main.avg_p * main.quantity\n",
    "        main.sort_values(['no','date_no'], inplace = True)\n",
    "        \n",
    "        # 新增前59天JOIN KEY\n",
    "        for i in range(1,60):\n",
    "            main['key_{}'.format(i)] = main['date_no'] - i\n",
    "            main['key_{}'.format(i)] = main['key_{}'.format(i)].astype('category')\n",
    "        \n",
    "        # tmp為LEFT JOIN的表格 ，只留需計算的欄位\n",
    "        tmp = main[['no','date_no','amount','quantity','close']]\n",
    "        \n",
    "        # 取得處理日期的DATE_NO , 並留下需insert的日期資料\n",
    "        iD = '{:0>4}-{:0>2}-{:0>2}'.format(iD.year,iD.month,iD.day)\n",
    "        ino = pandas.read_sql(\"select distinct date_no , date from work_date where date = '{}'\".format(iD) , con = conn)['date_no'][0]\n",
    "        main = main[main['date_no'] == ino]\n",
    "        \n",
    "        print('Start : \\033[1mMERGE\\033[0m data within 60 days')\n",
    "        \n",
    "        # 將60天內的資料合併成一列 , 並刪除join key\n",
    "        for i in range(1,60):\n",
    "            main = pandas.merge(main , tmp , left_on = ['no','key_{}'.format(i)] , right_on = ['no','date_no'] , suffixes = ('','_y_{}'.format(i)))\n",
    "            main.drop(['date_no_y_{}'.format(i),'key_{}'.format(i)], axis = 1 , inplace = True)\n",
    "        \n",
    "        print('Start : \\033[1mAGGREGATE\\033[0m close & average price')   \n",
    "        \n",
    "        # 計算各頻率 SMA & AVG\n",
    "        freq = [5,10,20,60]\n",
    "        for f in freq:\n",
    "            main['sma_{}'.format(f)] = round(main.filter(like = 'close').iloc[:,:f].mean(axis =1),2)\n",
    "            main['amt_{}'.format(f)] = main.filter(like = 'amount').iloc[:,:f].sum(axis =1)\n",
    "            main['qty_{}'.format(f)] = main.filter(like = 'quantity').iloc[:,:f].sum(axis =1)\n",
    "            main['avg_{}'.format(f)] = round((main['amt_{}'.format(f)] / main['qty_{}'.format(f)]),2)\n",
    "            main.drop(['amt_{}'.format(f),'qty_{}'.format(f)] , axis = 1 , inplace = True)\n",
    "            \n",
    "        # 刪除不需要INSERT的欄位\n",
    "        main.drop(main.filter(regex=r'amount\\_') , axis = 1 , inplace = True )\n",
    "        main.drop(main.filter(regex=r'close\\_') , axis = 1 , inplace = True )\n",
    "        main.drop(main.filter(regex=r'quantity\\_') , axis = 1 , inplace = True )\n",
    "        main['date_no'] = pandas.read_sql(\"select date_no from work_date where date = '{}'\".format(iD) , con = conn )['date_no'][0]\n",
    "        main = main[['date','no','name','close','avg_p','avg_5','avg_10','avg_20','avg_60','sma_5','sma_10','sma_20','sma_60','date_no']]\n",
    "        \n",
    "        print('Start : \\033[1mINSERT\\033[0m to target table')\n",
    "        \n",
    "        if main.shape[0] == 0:\n",
    "            pass\n",
    "        else :\n",
    "            display(main.head(1))\n",
    "            for _ , data in main.iterrows():\n",
    "                cur.execute(\"insert into ods.analyze_avg (date ,no ,name , close ,avg_p ,avg5 ,avg10 ,avg20 ,avg60 ,sma5 ,sma10 ,sma20 ,sma60 , date_no) \\\n",
    "                values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\" , data)\n",
    "        \n",
    "            cur.execute('commit')\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Aggregate 】- Foreign Investor OBS Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FI_OBS_SUM(work_D , cursor):\n",
    "    insert_D = work_D\n",
    "    cur = cursor\n",
    "    \n",
    "    for iD in insert_D:\n",
    "\n",
    "        #iD=datetime.datetime.today()\n",
    "        D = '{:0>4}-{:0>2}-{:0>2}'.format(iD.year,iD.month,iD.day)\n",
    "        \n",
    "        # 取得所有股票代號 , 並分為五等份執行\n",
    "        stock_no = pandas.read_sql(\"select no from stock_daily union select no from otc_daily\",con = conn)\n",
    "        step = int((len(stock_no)/5)+0.5)\n",
    "        \n",
    "        # 初始化批次區間變數\n",
    "        x = 0\n",
    "        y = step\n",
    "        \n",
    "        for part in range(5):      \n",
    "            \n",
    "            process_stock = tuple(stock_no.iloc[x:y,0].values)\n",
    "            fi = pandas.read_sql(\"select distinct head.no , head.date , head.date_no , main.quantity \\\n",
    "                            from (select stock.* , wk.date_no \\\n",
    "                                    from (select no , date from stock_daily a where no in {0} union  select no , date from otc_daily b where no in {0}) stock \\\n",
    "                                    join work_date wk \\\n",
    "                                      on stock.date = wk.date) head \\\n",
    "                            left join (select distinct *  from foreign_investor ) main \\\n",
    "                              on head.no = main.no \\\n",
    "                             and head.date = main.date\".format(process_stock) , con = conn).fillna(0)\n",
    "            \n",
    "            fi_tmp = fi[['no','date_no','quantity']]\n",
    "            fi = fi[fi.date.astype('string') == D ]\n",
    "        \n",
    "            \n",
    "            for i in range(1,60):\n",
    "                fi['key_{}'.format(i)] = fi.date_no - i\n",
    "            \n",
    "            for i in range(1,60):\n",
    "                fi = pandas.merge(fi,fi_tmp , left_on = ['no','key_{}'.format(i)], right_on =['no','date_no'] , suffixes = ('','_y{}'.format(i)))\n",
    "        \n",
    "                fi.drop(['key_{}'.format(i),'date_no_y{}'.format(i)], axis = 1 , inplace = True)\n",
    "          \n",
    "            fi['fi_sum5'] = fi.filter(like='quantity').iloc[:,:5].sum(axis = 1)\n",
    "            fi['fi_sum10'] = fi.filter(like='quantity').iloc[:,:10].sum(axis = 1)\n",
    "            fi['fi_sum20'] = fi.filter(like='quantity').iloc[:,:20].sum(axis = 1)\n",
    "            fi['fi_sum60'] = fi.filter(like='quantity').iloc[:,:60].sum(axis = 1)\n",
    "            fi.drop(fi.filter(regex = 'quantity\\_').columns , axis =1 , inplace = True)\n",
    "            fi['date_no'] = pandas.read_sql(\"select date_no from work_date where date = '{}'\".format(D) , con = conn )['date_no'][0]\n",
    "            fi = fi[['no','date','quantity','fi_sum5','fi_sum10','fi_sum20','fi_sum60','date_no']]\n",
    "            display(fi.head(1))\n",
    "        \n",
    "            \n",
    "            for _ , data in fi.iterrows():\n",
    "                cur.execute('insert into ods.analyze_FI_OBS (no , date , quantity,sum5,sum10,sum20,sum60,date_no) \\\n",
    "            values (%s,%s,%s,%s,%s,%s,%s,%s)' , data)\n",
    "            \n",
    "            cur.execute('commit')\n",
    "            print('【 Tech Analyze Foreign Investor Over Bought / Sold 】{0} data inserted {1}/5 .'.format(D,part+1))\n",
    "            x = y\n",
    "            y += step\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Aggregate 】- Investment Trust OBS Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IT_OBS_SUM(work_D , cursor):\n",
    "    insert_D = work_D\n",
    "    cur = cursor\n",
    "    for iD in insert_D:\n",
    "    \n",
    "        #iD=datetime.datetime.today()\n",
    "        D = '{:0>4}-{:0>2}-{:0>2}'.format(iD.year,iD.month,iD.day)\n",
    "        \n",
    "        # 取得所有股票代號 , 並分為五等份執行\n",
    "        stock_no = pandas.read_sql(\"select no from stock_daily union select no from otc_daily\",con = conn)\n",
    "        step = int((len(stock_no)/5)+0.5)\n",
    "        \n",
    "        # 初始化批次區間變數\n",
    "        x = 0\n",
    "        y = step\n",
    "        \n",
    "        for part in range(5):      \n",
    "            \n",
    "            process_stock = tuple(stock_no.iloc[x:y,0].values)\n",
    "            fi = pandas.read_sql(\"select distinct head.no , head.date , head.date_no , main.quantity \\\n",
    "                                from (select stock.* , wk.date_no \\\n",
    "                                        from (select no , date from stock_daily a where no in {0} union  select no , date from otc_daily b where no in {0}) stock \\\n",
    "                                        join work_date wk \\\n",
    "                                      on stock.date = wk.date) head \\\n",
    "                            left join (select distinct * from investment_trust) main \\\n",
    "                              on head.no = main.no \\\n",
    "                             and head.date = main.date\".format(process_stock) , con = conn).fillna(0)\n",
    "            \n",
    "            fi_tmp = fi[['no','date_no','quantity']]\n",
    "            \n",
    "            fi = fi[fi.date.astype('string') == D ]\n",
    "            \n",
    "            \n",
    "            for i in range(1,60):\n",
    "                fi['key_{}'.format(i)] = fi.date_no - i\n",
    "                \n",
    "            for i in range(1,60):\n",
    "                fi = pandas.merge(fi,fi_tmp , left_on = ['no','key_{}'.format(i)], right_on =['no','date_no'] , suffixes = ('','_y{}'.format(i)))\n",
    "                \n",
    "                fi.drop(['key_{}'.format(i),'date_no_y{}'.format(i)], axis = 1 , inplace = True)\n",
    "            \n",
    "            fi['it_sum5'] = fi.filter(like='quantity').iloc[:,:5].sum(axis = 1)\n",
    "            fi['it_sum10'] = fi.filter(like='quantity').iloc[:,:10].sum(axis = 1)\n",
    "            fi['it_sum20'] = fi.filter(like='quantity').iloc[:,:20].sum(axis = 1)\n",
    "            fi['it_sum60'] = fi.filter(like='quantity').iloc[:,:60].sum(axis = 1)\n",
    "            fi.drop(fi.filter(regex = 'quantity\\_').columns , axis =1 , inplace = True)\n",
    "            fi['date_no'] = pandas.read_sql(\"select date_no from work_date where date = '{}'\".format(D) , con = conn )['date_no'][0]\n",
    "            fi = fi[['no','date','quantity','it_sum5','it_sum10','it_sum20','it_sum60','date_no']]\n",
    "            display(fi.head(1))\n",
    "        \n",
    "            \n",
    "            for _ , data in fi.iterrows():\n",
    "                cur.execute('insert into ods.analyze_IT_OBS (no , date , quantity,sum5,sum10,sum20,sum60,date_no) \\\n",
    "            values (%s,%s,%s,%s,%s,%s,%s,%s)' , data)\n",
    "            \n",
    "            cur.execute('commit')\n",
    "            print('【 Tech Analyze Investment Trust Over Bought / Sold 】{0} data inserted {1}/5 .'.format(D,part+1))\n",
    "            x = y\n",
    "            y += step\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Aggregate 】- Dealer OBS Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_OBS_SUM(work_D,cursor):\n",
    "    insert_D = work_D\n",
    "    cur = cursor\n",
    "    for iD in insert_D:\n",
    "    \n",
    "        #iD=datetime.datetime.today()\n",
    "        D = '{:0>4}-{:0>2}-{:0>2}'.format(iD.year,iD.month,iD.day)\n",
    "        \n",
    "        # 取得所有股票代號 , 並分為五等份執行\n",
    "        stock_no = pandas.read_sql(\"select no from stock_daily union select no from otc_daily\",con = conn)\n",
    "        step = int((len(stock_no)/5)+0.5)\n",
    "        \n",
    "        # 初始化批次區間變數\n",
    "        x = 0\n",
    "        y = step\n",
    "        \n",
    "        for part in range(5):      \n",
    "            \n",
    "            process_stock = tuple(stock_no.iloc[x:y,0].values)\n",
    "            dl = pandas.read_sql(\"select distinct head.no , head.date , head.date_no , main.quantity \\\n",
    "                            from (select stock.* , wk.date_no \\\n",
    "                                    from (select no , date from stock_daily a where no in {0} union  select no , date from otc_daily b where no in {0}) stock \\\n",
    "                                    join work_date wk \\\n",
    "                                      on stock.date = wk.date) head \\\n",
    "                            left join (select distinct *  from dealer ) main \\\n",
    "                              on head.no = main.no \\\n",
    "                             and head.date = main.date\".format(process_stock) , con = conn).fillna(0)\n",
    "            \n",
    "            dl_tmp = dl[['no','date_no','quantity']]\n",
    "            dl = dl[dl.date.astype('string') == D ]\n",
    "    \n",
    "        \n",
    "            for i in range(1,60):\n",
    "                dl['key_{}'.format(i)] = dl.date_no - i\n",
    "            \n",
    "            for i in range(1,60):\n",
    "                dl = pandas.merge(dl,dl_tmp , left_on = ['no','key_{}'.format(i)], right_on =['no','date_no'] , suffixes = ('','_y{}'.format(i)))\n",
    "        \n",
    "                dl.drop(['key_{}'.format(i),'date_no_y{}'.format(i)], axis = 1 , inplace = True)\n",
    "          \n",
    "            dl['dl_sum5'] = dl.filter(like='quantity').iloc[:,:5].sum(axis = 1)\n",
    "            dl['dl_sum10'] = dl.filter(like='quantity').iloc[:,:10].sum(axis = 1)\n",
    "            dl['dl_sum20'] = dl.filter(like='quantity').iloc[:,:20].sum(axis = 1)\n",
    "            dl['dl_sum60'] = dl.filter(like='quantity').iloc[:,:60].sum(axis = 1)\n",
    "            dl.drop(dl.filter(regex = 'quantity\\_').columns , axis =1 , inplace = True)\n",
    "            dl['date_no'] = pandas.read_sql(\"select date_no from work_date where date = '{}'\".format(D) , con = conn )['date_no'][0]\n",
    "            dl = dl[['no','date','quantity','dl_sum5','dl_sum10','dl_sum20','dl_sum60','date_no']]\n",
    "            display(dl.head(1))\n",
    "        \n",
    "            \n",
    "            for _ , data in dl.iterrows():\n",
    "                cur.execute('insert into ods.analyze_DL_OBS (no , date , quantity,sum5,sum10,sum20,sum60,date_no) \\\n",
    "            values (%s,%s,%s,%s,%s,%s,%s,%s)' , data)\n",
    "            \n",
    "            cur.execute('commit')\n",
    "            print('【 Tech Analyze Dealer Over Bought / Sold 】{0} data inserted {1}/5 .'.format(D,part+1))\n",
    "            x = y\n",
    "            y += step\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Technology Analyse 】- MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(work_D , cursor , n = 12 , m = 26 , x = 9 ):\n",
    "    n = 12\n",
    "    m = 26\n",
    "    x = 9\n",
    "    \n",
    "    for insert_D in work_D:\n",
    "\n",
    "        D = '{:0>4}-{:0>2}-{:0>2}'.format(insert_D.year,insert_D.month,insert_D.day)\n",
    "        all_stock = pandas.read_sql(\"select no from stock_daily where date = '{0}' union select no from otc_daily where date = '{0}'\".format(D) , con = conn)['no']\n",
    "        \n",
    "        for i_stock in range(len(all_stock)):\n",
    "            \n",
    "            TA = all_stock[i_stock]\n",
    "            today = pandas.read_sql(\"select m.* , d.date_no from (select date , no , close  from stock_daily where no = '{0}'  union select date , no , close  from otc_daily where no = '{0}' ) m \\\n",
    "                                                            join work_date d \\\n",
    "                                                              on m.date = d.date \\\n",
    "                                                           where d.date = '{1}' \".format(TA , D) , con = conn)\n",
    "            today[['nEMA','mEMA','DIF','MACD','BAR']] = 0.0\n",
    "            date_no = today['date_no'][0]\n",
    "            yesterday = pandas.read_sql(\"select date , date_no , no , nEMA , mEMA , MACD from ods.macd where no = '{0}' and date_no = {1}\".format(TA , date_no-1) , con = conn)\n",
    "            \n",
    "            if yesterday.shape[0] == 0:\n",
    "                today['nEMA'] = today['close'] * 2 / (n + 1)\n",
    "                today['mEMA'] = today['close'] * 2 / (m + 1)\n",
    "                today['DIF'] = today['nEMA'] - today['mEMA']\n",
    "                today['MACD'] = today['DIF'] * 2 / (x + 1)\n",
    "                today['BAR'] = today['DIF'] - today['MACD']\n",
    "        \n",
    "            else:\n",
    "                today['nEMA'] = ((yesterday['nema'][0] * (n - 1)) + (today['close'] * 2)) / (n + 1)\n",
    "                today['mEMA'] = ((yesterday['mema'][0] * (m - 1)) + (today['close'] * 2)) / (m + 1)\n",
    "                today['DIF'] = today['nEMA'] - today['mEMA']\n",
    "                today['MACD'] = ((yesterday['macd'][0] * (x - 1)) + today['DIF'][0] * 2) / (x + 1)\n",
    "                today['BAR'] = today['DIF'] - today['MACD']\n",
    "            today[['BAR','nEMA','mEMA','MACD']] = round(today[['BAR','nEMA','mEMA','MACD']],3)     \n",
    "            today = today[['date','date_no','no','BAR','nEMA','mEMA','MACD']]\n",
    "        \n",
    "            for _,data in today.iterrows():\n",
    "                \n",
    "                cur.execute(\"insert into ods.macd (date , date_no , no , macd_bar , nema , mema , macd) values (%s,%s,%s,%s,%s,%s,%s)\",data)\n",
    "            cur.execute(\"commit\")\n",
    "            \n",
    "        print(\"【 MACD 】{} data inserted. \".format(insert_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Technology Analyse 】- CCT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCT5(work_D , cursor ):\n",
    "\n",
    "    for D in work_D:\n",
    "        \n",
    "        insert_D = '{:0>4}-{:0>2}-{:0>2}'.format(D.year,D.month,D.day)\n",
    "        \n",
    "        # 取得股市中的5天內的日期\n",
    "        html_D = pandas.read_sql(\"select y.date as first_day ,t.date as last_day \\\n",
    "                                    from work_date t \\\n",
    "                                    join work_date y \\\n",
    "                                      on t.date_no - 4 = y.date_no \\\n",
    "                                   where t.date = '{0}'\".format(insert_D) , con = conn)\n",
    "        # 排除週一到週五但無股市的日期\n",
    "        if html_D.shape[0] != 0:\n",
    "            \n",
    "            first_D = str(html_D['first_day'][0])\n",
    "            last_D = str(html_D['last_day'][0])\n",
    "            \n",
    "            # 讀取處理日期中的所有股票編號\n",
    "            all_stock = pandas.read_sql(\"select main.no  from (select no from stock_daily where date = '{0}' union select no from otc_daily where date = '{0}') main left join (select no from ods.cct5 where date = '{0}') c on c.no = main.no where c.no is null and main.no != '1418'\".format(insert_D),con = conn)\n",
    "    \n",
    "            for i in range(len(all_stock)):\n",
    "                TA = all_stock['no'][i]\n",
    "                \n",
    "                # 讀取當日以前的交易量\n",
    "                QTY = pandas.read_sql(\"select * from (select date , no , quantity from stock_daily where no = '{0}' and date <= '{1}' union select date , no , quantity from otc_daily where no = '{0}' and date <= '{1}') a order by date\".format(TA,insert_D) , con = conn)\n",
    "                # 判斷此股票是否有5天的交易日\n",
    "                if len(QTY) >= 5:\n",
    "                    \n",
    "                    sum5 = QTY['quantity'].iloc[-5:].sum()\n",
    "                    #html = 'http://sod.nsc.com.tw/z/zc/zco/zco.djhtm?a={0}&e={1}&f={2}'.format(TA,first_D,last_D)\n",
    "                    html = 'https://fubon-ebrokerdj.fbs.com.tw/z/zc/zco/zco.djhtm?a={0}&e={1}&f={2}'.format(TA,first_D,last_D)\n",
    "                    main = pandas.read_html(html)[2].iloc[-3,[1,6]]\n",
    "                    \n",
    "                    # 排除20日內無主力交易\n",
    "                    if main[1] != '買超':\n",
    "                    \n",
    "                        cct5 = round((int(main[1]) - int(main[6]))/sum5,4)\n",
    "                        date_no = pandas.read_sql(\"select date_no from work_date where date = '{}'\".format(insert_D) , con = conn )['date_no'][0]\n",
    "                        insert_data = pandas.DataFrame([[insert_D,TA,cct5,date_no]],columns = ['date','no','cct5','date_no'])\n",
    "                        \n",
    "                        for _ , data in insert_data.iterrows():\n",
    "                            try:\n",
    "                                cur.execute(\"insert into ods.cct5 (date , no , cct5,date_no) values (%s,%s,%s,%s)\",data)\n",
    "                            except :\n",
    "                                cur.execute(\"insert into ods.cct5 (date , no , cct5,date_no) values (%s,%s,%s,%s)\",(insert_D,TA,99.9999,date_no))\n",
    "                        \n",
    "                        cur.execute(\"commit\")\n",
    "                        if (i+1)%100 == 0:\n",
    "                            print('{}  {:>5} / {:>5}'.format(insert_D , i+1,len(all_stock)))\n",
    "                        elif (i+1)%len(all_stock) ==0:\n",
    "                            print('{}  {:>5} / {:>5}'.format(insert_D , i+1,len(all_stock)))\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                else :\n",
    "                    pass\n",
    "        else :\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Technology Analyse 】- CCT20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCT20(work_D , cursor ):\n",
    "\n",
    "    for D in work_D:\n",
    "        \n",
    "        insert_D = '{:0>4}-{:0>2}-{:0>2}'.format(D.year,D.month,D.day)\n",
    "        \n",
    "        # 取得股市中的19天前的日期\n",
    "        html_D = pandas.read_sql(\"select y.date as first_day ,t.date as last_day \\\n",
    "                                    from work_date t \\\n",
    "                                    join work_date y \\\n",
    "                                      on t.date_no - 19 = y.date_no \\\n",
    "                                   where t.date = '{0}'\".format(insert_D) , con = conn)\n",
    "        \n",
    "        # 排除週一到週五但無股市的日期\n",
    "        if html_D.shape[0] !=0:\n",
    "            \n",
    "            first_D = str(html_D['first_day'][0])\n",
    "            last_D = str(html_D['last_day'][0])\n",
    "            \n",
    "            # 讀取處理日期中的所有股票編號\n",
    "            all_stock = pandas.read_sql(\"select main.no  from (select no from stock_daily where date = '{0}' union select no from otc_daily where date = '{0}') main left join (select no from ods.cct20 where date = '{0}') c on c.no = main.no where c.no is null and main.no != '1418'\".format(insert_D),con = conn)\n",
    "    \n",
    "            for i in range(len(all_stock)):\n",
    "            \n",
    "                TA = all_stock['no'][i]\n",
    "                \n",
    "                # 讀取當日以前的交易量\n",
    "                QTY = pandas.read_sql(\"select * from (select date , no , quantity from stock_daily where no = '{0}' and date <= '{1}' union select date , no , quantity from otc_daily where no = '{0}' and date <= '{1}') a order by date\".format(TA,insert_D) , con = conn)               \n",
    "                \n",
    "                # 判斷此股票是否有20天的交易日\n",
    "                if len(QTY) >= 20:\n",
    "                    \n",
    "                    sum20 = QTY['quantity'].iloc[-20:].sum()\n",
    "                    #html = 'http://sod.nsc.com.tw/z/zc/zco/zco.djhtm?a={0}&e={1}&f={2}'.format(TA,first_D,last_D)\n",
    "                    html = 'https://fubon-ebrokerdj.fbs.com.tw/z/zc/zco/zco.djhtm?a={0}&e={1}&f={2}'.format(TA,first_D,last_D)\n",
    "                    main = pandas.read_html(html)[2].iloc[-3,[1,6]]\n",
    "                    \n",
    "                    # 排除20日內無主力交易\n",
    "                    if main[1] != '買超':\n",
    "                    \n",
    "                        cct20 = round((int(main[1]) - int(main[6]))/sum20,4)\n",
    "                        date_no =pandas.read_sql(\"select date_no from work_date where date = '{}'\".format(insert_D) , con = conn )['date_no'][0]\n",
    "                        insert_data = pandas.DataFrame([[insert_D,TA,cct20,date_no]],columns = ['date','no','cct20','date_no'])\n",
    "                        \n",
    "                        for _ , data in insert_data.iterrows():\n",
    "                            \n",
    "                            try:\n",
    "                                cur.execute(\"insert into ods.cct20 (date , no , cct20,date_no) values (%s,%s,%s,%s)\",data)\n",
    "                            except :\n",
    "                                cur.execute(\"insert into ods.cct20 (date , no , cct20,date_no) values (%s,%s,%s,%s)\",(insert_D,TA,99.9999,date_no))\n",
    "                        cur.execute(\"commit\")\n",
    "                        if (i+1)%100 == 0:\n",
    "                            print('{}  {:>5} / {:>5}'.format(insert_D , i+1,len(all_stock)))\n",
    "                        elif (i+1)%len(all_stock) ==0 :\n",
    "                            print('{}  {:>5} / {:>5}'.format(insert_D , i+1,len(all_stock)))\n",
    "                                \n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                else :\n",
    "                    pass\n",
    "        else :\n",
    "            pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Technology Analyse 】- KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KD(work_D , cur):\n",
    "    for D in work_D:\n",
    "        insert_D = '{:0>4}-{:0>2}-{:0>2}'.format(D.year,D.month,D.day)\n",
    "        all_list = pandas.read_sql(\"select main.no from (select date,no from stock_daily where date = '{0}'  union \\\n",
    "                         select date , no from otc_daily where date = '{0}' ) main left join ods.kd k on main.date =k.date and main.no = k.no where k.no is null\".format(insert_D) , con = conn)['no'].tolist()\n",
    "        \n",
    "        date_list = tuple(pandas.read_sql(\"select cast(date as varchar) from work_date where date_no >= (select date_no from work_date where date = '{0}') -8 \\\n",
    "                                              and date_no <= (select date_no from work_date where date = '{0}')\".format(insert_D) , con = conn)['date'].tolist())\n",
    "        try :\n",
    "            date_no = str(pandas.read_sql(\"select date_no from work_date where date = '{0}'\".format(insert_D) , con = conn)['date_no'][0])\n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "        for no in range(len(all_list)):\n",
    "            kd_ini = pandas.read_sql(\"select * from ods.kd where no = '{0}'\".format(all_list[no]) , con = conn)\n",
    "            if len(kd_ini) < 8 :           \n",
    "                cur.execute(\"insert into ods.kd (date ,date_no, no , k_value , d_value) values (%s,%s,%s,%s,%s)\" , (insert_D ,date_no , all_list[no] , 50,50))\n",
    "                \n",
    "            else :\n",
    "                \n",
    "                process_no = pandas.read_sql(\"select * from (select date , no , close , highest , lowest from stock_daily where no = '{0}' and date in {1} union \\\n",
    "                                                             select date , no , close , highest , lowest from   otc_daily where no = '{0}' and date in {1}) main \\\n",
    "                                                      order by date \".format(all_list[no],date_list) , con = conn)\n",
    "                #display(process_no)\n",
    "                min_9 = process_no[process_no['lowest']>0]['lowest'].min()\n",
    "                max_9 = process_no[process_no['highest']>0]['highest'].max()\n",
    "                if min_9 == max_9:\n",
    "                    RSV = 0\n",
    "                else :\n",
    "                    #display(process_no[process_no['close']>0])\n",
    "                    #display(all_list[no])\n",
    "                    try:\n",
    "                        RSV = ((process_no[process_no['close']>0]['close'].iloc[-1]-min_9) / (max_9 - min_9))*100\n",
    "                        last_kd = pandas.read_sql(\"select k_value , d_value from ods.kd where no = '{0}' order by date desc limit 1\".format(all_list[no],date_list[-2]) , con = conn)\n",
    "                        last_k = last_kd['k_value'][0]\n",
    "                        last_d = last_kd['d_value'][0]            \n",
    "                        \n",
    "                        today_k = (last_k/3)*2 + (RSV/3)\n",
    "                        today_d = (last_d/3)*2 + (today_k/3)\n",
    "                        #print(RSV,today_k , today_d)\n",
    "                \n",
    "                        cur.execute(\"insert into ods.kd (date , date_no , no , k_value , d_value) values (%s,%s,%s,%s,%s)\" , (insert_D , date_no , all_list[no] , today_k , today_d))\n",
    "                        cur.execute(\"commit\")        \n",
    "        \n",
    "                    except IndexError:\n",
    "                        pass\n",
    "        if len(all_list) == 0:\n",
    "            print(\"【 KD 】{0} no need to inserted .\".format(insert_D))\n",
    "        else :\n",
    "            print(\"【 KD 】{0} data inserted .\".format(insert_D))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Technology Analyse 】- BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIAS(work_D,cur):\n",
    "    for D in work_D:\n",
    "        insert_D = '{:0>4}-{:0>2}-{:0>2}'.format(D.year,D.month,D.day)\n",
    "        \n",
    "        all_list = pandas.read_sql(\"select main.no \\\n",
    "                                      from (select date,no from stock_daily where date = '{0}'  union \\\n",
    "                                            select date , no from otc_daily where date = '{0}' ) main \\\n",
    "                                              join ods.analyze_avg avg \\\n",
    "                                                on avg.no = main.no \\\n",
    "                                               and avg.date = main.date \\\n",
    "                                              left join ods.bias b \\\n",
    "                                                on main.date = b.date \\\n",
    "                                               and main.no = b.no \\\n",
    "                                     where b.no is null\".format(insert_D) , con = conn)['no'].tolist()\n",
    "        \n",
    "        if len(all_list) == 0:\n",
    "            print(\"【 BIAS 】{0} no need to inserted .\".format(insert_D))\n",
    "        else :\n",
    "            for i in range(len(all_list)):\n",
    "                main = pandas.read_sql(\"select * from ods.analyze_avg where date = '{0}' and no = '{1}'\".format(insert_D,all_list[i]) , con = conn)\n",
    "                main['bias_5'] = round((main['close'][0] - main['sma5'][0])/main['sma5'][0],4)\n",
    "                main['bias_20'] = round((main['close'][0] - main['sma20'][0])/main['sma20'][0],4)\n",
    "                main = main[['date','date_no','no','bias_5','bias_20']]\n",
    "                \n",
    "                for _,data in main.iterrows():                                 \n",
    "                    cur.execute(\"insert into ods.bias (date , date_no , no , bias_5,bias_20) values (%s,%s,%s,%s,%s)\",data)\n",
    "                cur.execute(\"commit\")\n",
    "                \n",
    "                \n",
    "            print(\"【 BIAS 】{0} inserted .\".format(insert_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Report 】- FI Exponent Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FI_EXPONENT_ENERGY(work_D,cur):\n",
    "    for D in work_D:\n",
    "        \n",
    "        # 串聯classify , institutional_investor , analyze_avg 取得投信及外資進出數量及成本\n",
    "        insert_D = '{:0>4}-{:0>2}-{:0>2}'.format(D.year,D.month,D.day)\n",
    "        \n",
    "        FI = pandas.read_sql(\"select head.type , head.classify , head.date ,head.date_no , body.no , body.qty , body.amt \\\n",
    "                                from (select distinct date , date_no , type , classify from classify c , work_date d where d.date = '{0}') head \\\n",
    "                                left join (select main.date , d.date_no ,  main.no , c.type , c.classify , main.qty , main.amt \\\n",
    "                                        from (select fi.date , fi.no , fi.quantity as qty , fi.quantity * avg.price as AMT \\\n",
    "                                             from FOREIGN_INVESTOR fi \\\n",
    "                                             join STOCK_DAILY_AVG_PRICE avg \\\n",
    "                                               on fi.date = avg.date \\\n",
    "                                              and fi.no = avg.no ) main \\\n",
    "                                             join CLASSIFY c \\\n",
    "                                               on main.no = c.no \\\n",
    "                                             join work_date d \\\n",
    "                                               on main.date = d.date \\\n",
    "                                            where main.date = '{0}' ) body \\\n",
    "                                  on head.type = body.type \\\n",
    "                                 and head.classify = body.classify \\\n",
    "                                 and head.date = body.date \".format(insert_D) \n",
    "                        , con = conn)\n",
    "        \n",
    "        # 排除insert_D為非股市日\n",
    "        if FI.shape[0] != 0 :\n",
    "            #依照組別type, topic 加總金額及數量\n",
    "            agg = FI[['type','classify','qty','amt']].groupby(['type','classify']).sum().reset_index()\n",
    "            agg['date'] = FI['date'][0]\n",
    "            agg['date_no'] = FI['date_no'][0]\n",
    "            agg['investor'] = 'Foreign investor'\n",
    "            agg[['amt','qty']].fillna(0)\n",
    "            agg = agg[['date','date_no','type','classify','qty','amt','investor']]\n",
    "            \n",
    "            \n",
    "            for _ , data in agg.iterrows():\n",
    "                cur.execute(\"insert into ods.exponent_insti (date , date_no , type , topic , qty , amt , investor ) values (%s,%s,%s,%s,%s,%s,%s)\",data)\n",
    "            cur.execute('commit')\n",
    "            \n",
    "            print('【 Exponent Institutional 】{} Foreign Investor inserted. '.format(insert_D))\n",
    "            agg = ''\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # 取得所有 type , topic\n",
    "        \n",
    "        all_type = pandas.read_sql(\"select distinct type from classify \",con = conn)\n",
    "        \n",
    "        \n",
    "        for i_type in range(len(all_type)):   \n",
    "        \n",
    "            TYPE = all_type.iloc[i_type][0]\n",
    "           \n",
    "            all_topic = pandas.read_sql(\"select distinct classify from classify where type = '{}'\".format(TYPE) , con = conn)\n",
    "            for i_topic in range(len(all_topic)):\n",
    "                \n",
    "                TOPIC = all_topic.iloc[i_topic][0]\n",
    "                \n",
    "                main = pandas.read_sql(\"select * from ods.exponent_insti \\\n",
    "                                         where type = '{0}' \\\n",
    "                                           and topic = '{1}' \\\n",
    "                                           and investor = 'Foreign investor' \\\n",
    "                                           and date_no >= (select date_no from work_date where date = '{2}')-19 \\\n",
    "                                           and date_no <= (select date_no from work_date where date = '{2}') \\\n",
    "                                         order by date \".format(TYPE , TOPIC,insert_D) , con = conn)\n",
    "                \n",
    "                if len(main) == 20:\n",
    "                    main['qty20'].iloc[-1] = main['qty'].sum()\n",
    "                    main['amt20'].iloc[-1] = main['amt'].sum()\n",
    "                    DATE = main['date'].iloc[-1]\n",
    "                    #display(main.iloc[-1])\n",
    "                    \n",
    "                    cur.execute(\"update ods.exponent_insti set qty20 = '{0}' , amt20 = '{1}' \\\n",
    "                                  where date = '{2}' and type = '{3}' and topic = '{4}' and investor = 'Foreign investor'\".format(main['qty20'].iloc[-1],main['amt20'].iloc[-1],DATE,TYPE,TOPIC))\n",
    "                    \n",
    "                    cur.execute(\"commit\")\n",
    "                else:\n",
    "                    pass\n",
    "        print('【 Exponent Institutional 】{0} qty20 & amt20 of Foreign Investor updated.'.format(insert_D))\n",
    "                  \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Report 】- IT Exponent Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IT_EXPONENT_ENERGY(work_D,cur):\n",
    "    for D in work_D:\n",
    "        \n",
    "        # 串聯classify , institutional_investor , analyze_avg 取得投信及外資進出數量及成本\n",
    "        insert_D = '{:0>4}-{:0>2}-{:0>2}'.format(D.year,D.month,D.day)\n",
    "        \n",
    "        IT = pandas.read_sql(\"select head.type , head.classify , head.date ,head.date_no , body.no , body.qty , body.amt \\\n",
    "                                from (select distinct date , date_no , type , classify from classify c , work_date d where d.date = '{0}') head \\\n",
    "                                left join (select main.date , d.date_no ,  main.no , c.type , c.classify , main.qty , main.amt \\\n",
    "                                        from (select it.date , it.no , it.quantity as qty , it.quantity * avg.price as AMT \\\n",
    "                                             from INVESTMENT_TRUST it \\\n",
    "                                             join STOCK_DAILY_AVG_PRICE avg \\\n",
    "                                               on it.date = avg.date \\\n",
    "                                              and it.no = avg.no ) main \\\n",
    "                                             join CLASSIFY c \\\n",
    "                                               on main.no = c.no \\\n",
    "                                             join work_date d \\\n",
    "                                               on main.date = d.date \\\n",
    "                                            where main.date = '{0}' ) body \\\n",
    "                                  on head.type = body.type \\\n",
    "                                 and head.classify = body.classify \\\n",
    "                                 and head.date = body.date \".format(insert_D) \n",
    "                        , con = conn)\n",
    "        \n",
    "        # 排除insert_D為非股市日\n",
    "        if IT.shape[0] != 0 :\n",
    "            #依照組別type, topic 加總金額及數量\n",
    "            agg = IT[['type','classify','qty','amt']].groupby(['type','classify']).sum().reset_index()\n",
    "            agg['date'] = IT['date'][0]\n",
    "            agg['date_no'] = IT['date_no'][0]\n",
    "            agg['investor'] = 'Investment trust'\n",
    "            agg = agg[['date','date_no','type','classify','qty','amt','investor']]\n",
    "            #display(agg)\n",
    "            \n",
    "            for _ , data in agg.iterrows():\n",
    "                cur.execute(\"insert into ods.exponent_insti (date , date_no , type , topic , qty , amt , investor ) values (%s,%s,%s,%s,%s,%s,%s)\",data)\n",
    "            cur.execute('commit')\n",
    "            \n",
    "            print('【 Exponent Institutional 】{} of Investment Trust inserted. '.format(insert_D))\n",
    "            agg = ''\n",
    "        else:\n",
    "            pass\n",
    "        # 取得所有 type , topic\n",
    "        \n",
    "        all_type = pandas.read_sql(\"select distinct type from classify \",con = conn)\n",
    "        \n",
    "        \n",
    "        for i_type in range(len(all_type)):   \n",
    "        \n",
    "            TYPE = all_type.iloc[i_type][0]\n",
    "           \n",
    "            all_topic = pandas.read_sql(\"select distinct classify from classify where type = '{}'\".format(TYPE) , con = conn)\n",
    "            for i_topic in range(len(all_topic)):\n",
    "                \n",
    "                TOPIC = all_topic.iloc[i_topic][0]\n",
    "                \n",
    "                main = pandas.read_sql(\"select * from ods.exponent_insti \\\n",
    "                                         where type = '{0}' \\\n",
    "                                           and topic = '{1}' \\\n",
    "                                           and investor = 'Investment trust' \\\n",
    "                                           and date_no >= (select date_no from work_date where date = '{2}')-19 \\\n",
    "                                           and date_no <= (select date_no from work_date where date = '{2}') \\\n",
    "                                         order by date \".format(TYPE , TOPIC,insert_D) , con = conn)\n",
    "                \n",
    "                if len(main) == 20:\n",
    "                    main['qty20'].iloc[-1] = main['qty'].sum()\n",
    "                    main['amt20'].iloc[-1] = main['amt'].sum()\n",
    "                    DATE = main['date'].iloc[-1]\n",
    "                    #display(main.iloc[-1])\n",
    "                    \n",
    "                    cur.execute(\"update ods.exponent_insti set qty20 = '{0}' , amt20 = '{1}' \\\n",
    "                                  where date = '{2}' and type = '{3}' and topic = '{4}' and investor = 'Investment trust'\".format(main['qty20'].iloc[-1],main['amt20'].iloc[-1],DATE,TYPE,TOPIC))\n",
    "                    \n",
    "                    cur.execute(\"commit\")\n",
    "                else:\n",
    "                    pass\n",
    "        print('【 Exponent Institutional 】{0} qty20 & amt20 of Investment trust updated.'.format(insert_D))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【 Distinct 】- Distinct Issued Amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DISTINCT_ISSUED_AMOUNTS(cur):\n",
    "    main = pandas.read_sql(\"select date , no , count(*) from issued_amounts group by date , no having count(*) > 1\" , con = conn)\n",
    "    main = main[['date','no']]\n",
    "    main['type'] = 'OTC'\n",
    "    for _ , data in main.iterrows():\n",
    "        cur.execute(\"delete from issued_amounts where date = %s and no = %s and type = %s\",data)\n",
    "    cur.execute(\"commit\")\n",
    "    \n",
    "    print('DISTINCT_ISSUED_AMOUNTS is finished .')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
